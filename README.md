# ğŸ“º YouTube Trendingâ€¯ETL Pipeline with ApacheÂ AirflowÂ 3

An endâ€‘toâ€‘end **dataâ€‘engineering portfolio project** that

1. **Extracts** the complete â€œTrending / Mostâ€‘Popularâ€ list from the YouTubeâ€¯Dataâ€¯API  
2. **Stores** the raw JSON in **Azureâ€¯Blobâ€¯Storage**  
3. **Transforms** and **loads** the data into an **Azureâ€‘hosted PostgreSQL** table  
4. **Cleans up** the raw file once each load succeeds  

The project is orchestrated by a single **ApacheÂ AirflowÂ 3 DAG** running in Docker, and demonstrates intermediateâ€‘level Airflow patterns: XComs, custom helpers, secret management, dynamic pagination, Azure + Postgres hooks, and sequential task dependencies.

---

## ğŸ”¥ Why this project?

| Career Skill | Where it shows |
|--------------|----------------|
| Cloudâ€‘native storage + compute | Uses AzureÂ Blob + AzureÂ PostgreSQL |
| Modern orchestration | AirflowÂ 3 in Docker, with custom hooks/operators |
| External APIs & OAuth keys | YouTubeÂ Dataâ€¯API v3, API key stored in Airflow Variables |
| Robust ETL design | Pagination, retries, idempotent loads, cleanup |
| Intermediate Airflow concepts | XComs, Trigger Rules, TaskGroups, provider packages |

Use it as a template for **any API â†’Â BlobÂ â†’Â Warehouse** workflow.

---

## ğŸ—‚ Folder Layout
```
youtube-etl-airflow/
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ youtube_full_etl.py      # The orchestration DAG
â”‚   â”œâ”€â”€ youtube_helpers.py       # YouTube API + pagination logic
â”‚   â””â”€â”€ blob_helpers.py          # Azure Blob helpers + transform/load
â”‚
â”œâ”€â”€ docker-compose.yaml          # Local Airflow stack
â”œâ”€â”€ requirements.txt             # Python deps (exported from container)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

| Layer | Stack |
|-------|-------|
| Orchestration | **ApacheÂ AirflowÂ 3.0** (Docker) |
| DataÂ Source   | **YouTubeÂ Dataâ€¯API v3** |
| RawÂ Storage   | **AzureÂ Blobâ€¯Storage** (container: `youtube-raw-data`) |
| Transform     | **pandas** (flatten JSON -> DataFrame) |
| Warehouse     | **AzureÂ Database for PostgreSQL** |
| Providers     | `apache-airflow-providers-microsoft-azure`, `apache-airflow-providers-postgres` |

---

## ğŸ› ï¸ Setup & RunÂ Locally

> **Prerequisites**: DockerÂ Desktop, Git, YouTubeÂ API key, Azure Storage account, Azure PostgreSQL instance.

1. **Clone**
   ```bash
   git clone https://github.com/<your-username>/youtube-etl-airflow.git
   cd youtube-etl-airflow
   ```

2. **Configure Airflow connections**
   | Connection ID | Type | What to enter |
   |---------------|------|---------------|
   | `azure_blob_conn` | *Azure Blob Storage* | Extra â†’ `{"connection_string": "DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...;EndpointSuffix=core.windows.net"}` |
   | `postgres_default` | *Postgres* | host, db, user, pwd, portÂ 5432, SSLÂ =Â require |
   | Variable          |  | `youtube_api_key = <YOUR_KEY>` |

3. **Spin up Airflow**
   ```bash
   docker compose up -d
   ```

4. **Create target table**
   ```sql
   CREATE SCHEMA IF NOT EXISTS test;
   CREATE TABLE test.youtube_trending_raw (
       video_id        TEXT,
       published_at    TIMESTAMP,
       channel_id      TEXT,
       channel_title   TEXT,
       title           TEXT,
       description     TEXT,
       category_id     INT,
       tags            TEXT,
       view_count      BIGINT,
       like_count      BIGINT,
       comment_count   BIGINT,
       blob_filename   TEXT,
       load_ts         TIMESTAMP DEFAULT now()
   );
   ```

5. **Enable & Trigger DAG**
   - Airflow UI â†’ `youtube_full_etl` â†’ **On** â†’ *Trigger*  
   - Watch tasks `fetch_and_upload â†’ process_blob` succeed.

---

## ğŸ—ï¸ DAG Architecture

```
fetch_and_upload   -->   process_blob
(YouTube API +          (download JSON,
Azure upload)            transform, load,
                         delete blob)
```
*Strict dependency chain prevents race conditions and guarantees exactlyâ€‘once processing.*

---

## ğŸ”‘ Key Implementation Details

| Feature | Code |
|---------|------|
| **Pagination** | `youtube_helpers.fetch_trending` loops through `nextPageToken` until all pages are fetched (â‰ˆâ€¯50Â per page). |
| **Temporary files** | Raw JSON saved to `/tmp`, then uploaded, then removed. |
| **XCom usage** | Upload task returns the blob name â†’ consumed by the processing task. |
| **Blob cleanup** | Blob deleted only after Postgres commit (`TriggerRule.ALL_SUCCESS`). |
| **Tag column** | Stored as plain CSV (`tag1,tag2,...`) to avoid Postgres array literal issues. |

---

## ğŸ“Š What You Can Demo

- **Airflow UI screenshots**: Graph view, logs, XComs.
- **Azure Portal**: container briefly holds raw JSON.
- **Postgres**: `SELECT COUNT(*) FROM test.youtube_trending_raw;`
- **Extensibility**: Easily swap Azure for S3/GCS or add a reporting DAG (e.g., EmailOperator to mail daily topâ€‘10 CSV).

---

## ğŸš€ Future Enhancements

- âœ… Change `tags` to `text[]` with psycopg2 `execute_values`.
- âœ… Add dataâ€‘quality checks (`GreatExpectationsOperator`).
- âœ… Deploy Airflow via Helm on AKS or use Astro/CloudÂ Composer.
- âœ… Build a PowerÂ BI dashboard on the warehouse table.
- âœ… Parameterize multiple regions via Airflow Variables + TaskGroups.

---

## ğŸ“ Author

**Nikhil H** â€“ *Data Engineer*  
[LinkedIn][https://www.linkedin.com/in/nikhilhanumanthaiah]

